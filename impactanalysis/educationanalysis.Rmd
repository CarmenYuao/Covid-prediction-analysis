---
title: "educationanalysis"
output: html_document
date: '2022-04-08'
editor_options: 
  markdown: 
    wrap: sentence
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

load related packages

```{r}
library(TSA)
library(urca)
library(tseries)
```

# Zoom

First, we discuss about the simplest situation - COVID's impact on zoom.
The exact question is: How does the SAH policy influence on the ultilize of Zoom, which represent people' change in work-coordinate way.

Why?

First, the intervention date is extremely clear.
<https://www.swissinfo.ch/eng/coronavirus_did-the-swiss-stay--at-home-during-the-coronavirus-lockdown-/45722614> The Swiss has a consist stay at home policy, which is not available in many countries.

Second, the impact effect comes on immediately.From our experience, courses are online on zoom if it is not in the classroom.

Third, searching for zoom can be assumed to reflect using for zoom in some degree.
accessing zoom via browser is the main way.

## Data Selection

We use the data from last 5 years with granularity of week.
Why?

1.  Granularity: the policy intervention is on March 16th, Monday.
    The granularity of month is too coarse for mid-term happened intervention.

2.  Ending Date: even though the SAH policy is cancelled now, the ending date is

    1.  <https://www.swissinfo.ch/eng/swiss-anti-covid-curbs-to-remain-at-least-until-end-of-february/47274772>.

    2.  <https://www.swissinfo.ch/eng/covid-19_coronavirus--the-situation-in-switzerland/45592192>

    3.  <https://www.swissinfo.ch/eng/switzerland-lifts-most-covid-19-restrictions/47352480?utm_campaign=teaser-in-channel&utm_source=swissinfoch&utm_medium=display&utm_content=o>

    The related policies are cancelled in 2022 mostly.
    The SAH policy cancel at 2022-02-03.
    Therefore to be convenient, we just set the ending date for 2022.
    We also think that abandoning a little data before exact policy is wise.

3.  Starting Date: The Starting Date is not very important, we use the date 5 years before now.
    The zoom is released on 2011.
    And there is an improvement to Data Collection System on 2016 for Google Trend.
    The Data after it is also very stable intuitively.
    There2fore the specific choice of starting date is not essential.

4.  Why do we use Swiss Data?
    First, we are in Swiss.
    Second, Swiss has consistent policy.
    Thus we use Swiss Data for our analysis

## Basic Data Analysis

load data and convert it to time series

```{r}
zoom.ch <- read.csv(file="../data/impact/zoomSwiss.csv")
zoom.isr <- read.csv(file="../data/impact/zoomISR.csv")
zoom.ch <- zoom.ch[(1:min(which(zoom.ch[,1] >= "2022-01-01"))-1),]
zoom.isr <- zoom.isr[(1:min(which(zoom.isr[,1] >= "2022-01-01"))-1),]
zoom.ts.ch <- ts(zoom.ch[,2])
zoom.ts.isr <- ts(zoom.isr[,2])
zoom.length <- dim(zoom.ch)[1]
stayathome.ch <- min(which(zoom.ch[,1] >= "2020-03-16"))-1
```

We have to mention that the basic form is not satisfying.
The indicator from Google Trend is scaled mandatorily.
The maximum in data must be 100, and the other count is proportion to it with rounded to integer.

understand the data directly
```{r}
plot(zoom.ts.ch, ylim=c(0,105),type="l",col="red", xlab="Week", ylab="search popularity", main="Google Search Trend for Zoom",xaxt="n")
lines(zoom.ts.isr,col="blue")
axis(1, at=seq(1, zoom.length, 5),labels=substring(zoom.ch[seq(1,zoom.length,5), 1],3), cex.axis = 0.4, las="2")
abline(v=stayathome.ch,col="grey",lty="dashed", lwd=2)
legend("topleft",legend=c("ISR","CH"),col=c("blue","red"),lwd=2)
```

```{r}
plot(log(zoom.ts.ch),type="l",col="red", xlab="Week", ylab="search popularity", main="Google Search Trend for Zoom",xaxt="n",ylim=c(0,5))
lines(log(zoom.ts.isr),col="blue")
axis(1, at=seq(1, zoom.length, 5),labels=substring(zoom.ch[seq(1,zoom.length,5), 1],3), cex.axis = 0.4, las="2")
abline(v=stayathome.ch,col="grey",lty="dashed", lwd=2)
legend("topleft",legend=c("ISR","CH"),col=c("blue","red"),lwd=2)
```
# Swiss
test the stability for the whole time series
```{r}
adf.test(zoom.ts.ch)
adf.test(log(zoom.ts.ch))
summary(ur.kpss(zoom.ts.ch))
summary(ur.kpss(log(zoom.ts.ch)))
```
KPSS is not stable, I think it is because there is trend.
ADF test is not important here, because we definitely need to eliminate the trend for intervention.

test stability for the time series before intervention.

```{r}
adf.test(zoom.ts.ch[1:(stayathome.ch-4)])
adf.test(log(zoom.ts.ch[1:(stayathome.ch-4)]))
summary(ur.kpss(zoom.ts.ch[1:(stayathome.ch-4)]))
summary(ur.kpss(log(zoom.ts.ch[1:(stayathome.ch-4)])))
```

First, there is no need to differetiate, we do not.
there seem to be trend before intervention.
We monitor it after analysis.

## Model Building

set up the intervention effect
```{r}
step <- rep(0, zoom.length)
step[stayathome.ch:zoom.length] <- 1
pulse <- rep(0,zoom.length)
pulse[stayathome.ch] <- 1
ramp <- rep(0, zoom.length)
ramp[stayathome.ch:zoom.length] <- (stayathome.ch:zoom.length) - (stayathome.ch-1)
```

Here is explanation for our modeling:

First, we use Gauss Distribution instead of Poisson Distribution, even though the data is actually counting data.

-   the original number of counting is unavailable.

-   And we believe the counting number is large enough for similar analysis with Gauss.

-   Even though there is R package for Poisson ARIMA(tscount, glarma), original ARIMA is used on Gaussian Data.

Second, we use log-transformation due to the following reasons.

-   The absolute difference between our data is very large.
    Protect ordinary data from outlier.

-   The variance is highly Heterogeneous before and after intervention log-transformation can make distribution more similar to normal distribution(Introductory Econometrics, Wooldridge).

Third

-   the intervention impact shape comes from the following thoughts People's habits for working & communication style should change permanently.
    *modeled as step*

-   After the pulse of policy, the popularity should regress to reasonable value in a short-term.
    *modeled as ramp.*

```{r}
time = 1:zoom.length
m<-arimax(log(zoom.ts.ch), order=c(2, 0, 0), xreg = data.frame(step, ramp, time))
m
```

We select the model from data: parsimony: all coefficient must be significant.
AIC should be as small as possible The model is selected after manually tuning parameter p. d is not necessary and q make mistake.

If we don't apply the log-transform, the result will be much worse.



### Model Evaluation

plot the model at first.

```{r}
plot(fitted(m), col="black",lty=2)
lines(log(zoom.ts.ch), col="blue")
```

We can see the predicted value close to ordinary time series data in general

We then understanding the model from its residuals

```{r}
plot(m$residuals,ylab="residuals", xlab="weeks",xaxt="n")
axis(1, at=seq(1, zoom.length, 5),labels=substring(zoom.ch[seq(1,zoom.length,5), 1],3), cex.axis = 0.4, las="2")
abline(v=stayathome.ch,col="grey",lty="dashed", lwd=2)
```
We can see that the residuals seem to be stable intuitively.
Notice there is an outlier which could be found on original time series plot.

test the autocorrelation and partial autocorrelation

```{r}
acf(resid(m)[-1],lag=50, main="residuals")
```
```{r}
pacf(resid(m)[-1],lag=50, main="residuals")
```

We can see that there is no significant autocorrelation.
We could regard the residuals as reasonable results.

Test the autocorrelation in our residuals

```{r}
adf.test(m$residuals)
summary(ur.kpss(m$residuals))
Box.test(m$residuals, lag = 60, type = "Ljung-Box")
```

The residual is stable from DF test & KPSS test, compared with our raw data!
The residuals passes the Box-Ljung test: we could regard it as white noise!

### Other Selection
```{r}
m.ar3<-arimax(log(zoom.ts.ch), order=c(3, 0, 0), xreg = data.frame(step, ramp))
m.ar3
```

worse AIC & insignificant coefficients

```{r}
m.stable <- arimax(log(zoom.ts.ch), order=c(2, 0, 0), xreg = data.frame(step, ramp))
m.stable
```

General Trend is significant and can improve result indeed.

```{r}
m.nocovid <- arimax(log(zoom.ts.ch[1:(stayathome.ch-4)]), order=c(0, 0, 0), xreg = data.frame(time[1:(stayathome.ch-4)]))
m.nocovid
summary(ur.kpss(m.nocovid$residuals))
```

Before intervention, it is also meaningful to have a general trend, which can pass the KPSS test for stability.

```{r}
m.season <- arimax(log(zoom.ts.ch), order=c(2, 0, 0), seasonal=list(order=c(1,0,0),period=52), xreg = data.frame(step, ramp,time))
m.season
```

test

```{r}
confint(m.season)
adf.test(m.season$residuals)
summary(ur.kpss(m.season$residuals))
Box.test(m.season$residuals, lag = 60, type = "Ljung-Box")
```
The coefficient for seasonal model is not significant to our noun but it is close to it.
The seasonality could decrease AIC slightly and the p-value for Box-Ljung test can also be slightly bigger.
We have more chance to admit the residuals are white noise.
Thus we could say considering the seasonal effect improve the model slightly.
Due to the parsimony, we regard it as a candidate model.

Here is explanation for seasonality in our situation.
In our experience, there should be seasonality for our data.
Because, one heavy use of zoom is online course.As is known, there is no online course in summer and winter vacation.
Therefore there should be a seasonality.
However, the seasonality might not be obvious.The effect of this seasonality is not harmonious before or after intervention and can be ignored compared with current fluctuation.


## Another Case: ISR
The school closed on March 14, 2020. The Stay at Home Policy Start from March 19, 2020. refer to
https://academic.oup.com/cid/article/73/12/2265/6103916?login=false
https://www.reuters.com/article/us-health-coronavirus-israel-idUSKBN21622D
We could use March 16 at intervention date.
From the above time pictures, we can know that the usage amount before intervention is too small to model.Therefore we only model the time series after intervention.

```{r}
zoom.cut.isr<- zoom.ts.isr[stayathome.ch:zoom.length] 
```

```{r}
adf.test(zoom.cut.isr)
adf.test(log(zoom.cut.isr))
summary(ur.kpss(zoom.cut.isr))
summary(ur.kpss(log(zoom.cut.isr)))
```
not stable in all meaning.

```{r}
ramp <- 1:length(zoom.cut.isr)
m.isr<-arimax(log(zoom.cut.isr), order=c(2, 0, 0), xreg = data.frame(ramp))
m.isr
```
Due to there are only few points, we could not consider seasonal model.

```{r}
plot(fitted(m.isr), col="black",lty=2)
lines(log(zoom.cut.isr), col="blue")
```

```{r}
plot(m.isr$residuals,ylab="residuals", xlab="weeks",xaxt="n")
```

```{r}
acf(resid(m.isr)[-1],lag=50, main="residuals")
pacf(resid(m.isr)[-1],lag=50, main="residuals")
```

```{r}
confint(m.isr)
adf.test(m.isr$residuals)
summary(ur.kpss(m.isr$residuals))
Box.test(m.isr$residuals, lag = 30, type = "Ljung-Box")
```

### Try model other models
differentiate
```{r}
adf.test(diff(zoom.cut.isr))
adf.test(diff(log(zoom.cut.isr)))
summary(ur.kpss(diff(zoom.cut.isr)))
summary(ur.kpss(diff(log(zoom.cut.isr))))
```

differentiate log seem to be quite stable, we plot it.
```{r}
plot(diff(log(zoom.cut.isr)),type="l")
```
```{r}
acf(diff(log(zoom.cut.isr)),lag=50)
pacf(diff(log(zoom.cut.isr)),lag=50)
```
model it
```{r}
m.isr.try<-arimax(diff(log(zoom.cut.isr)), order=c(1, 0, 0))
m.isr.try
```

evaluate it
```{r}
acf(resid(m.isr.try)[-1],lag=50, main="residuals")
pacf(resid(m.isr.try)[-1],lag=50, main="residuals")
confint(m.isr.try)
adf.test(m.isr.try$residuals)
summary(ur.kpss(m.isr.try$residuals))
Box.test(m.isr.try$residuals, lag = 50, type = "Ljung-Box")
```

